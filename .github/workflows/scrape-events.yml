name: Daily AI Event Aggregation

on:
  schedule:
    # Run daily at 6:00 AM and 6:00 PM UTC for real-time updates
    - cron: '0 6 * * *'  # 6 AM UTC daily
    - cron: '0 18 * * *' # 6 PM UTC daily

  # Allow manual trigger
  workflow_dispatch:

# Required permissions for the workflow
permissions:
  contents: write  # Allow pushing to the repository

jobs:
  aggregate-events:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          cd automation
          pip install -r requirements.txt

      - name: Create Google credentials file
        run: |
          cd automation
          echo '${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}' > google-service-account.json

      - name: Run AI Event Aggregator
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SHEET_ID }}
          GOOGLE_SHEETS_CREDENTIALS: ./google-service-account.json
          EVENTBRITE_API_KEY: ${{ secrets.EVENTBRITE_API_KEY }}
          FACEBOOK_ACCESS_TOKEN: ${{ secrets.FACEBOOK_ACCESS_TOKEN }}
          SCRAPE_DAYS_AHEAD: 90
          MIN_QUALITY_SCORE: 50
          AUTO_APPROVE_THRESHOLD: 80
          NORWICH_RADIUS_KM: 15
        run: |
          cd automation
          python ai-event-aggregator.py

      - name: Sync data to website
        run: |
          cd automation
          # Find the latest events file (check both naming patterns)
          LATEST_FILE=$(ls -t ai_events_*.json events_*.json 2>/dev/null | head -1 || echo "")

          if [ -n "$LATEST_FILE" ]; then
            echo "Found latest file: $LATEST_FILE"
            # Copy to website data directory (Python script may have already done this)
            cp "$LATEST_FILE" ../data/sample-events.json 2>/dev/null || echo "Already synced by Python script"
            echo "‚úÖ Data synced to website"
          else
            echo "‚ö†Ô∏è No events file found"
          fi

      - name: Commit and push updated data
        run: |
          git config user.name "AI Event Bot"
          git config user.email "bot@norwicheventshub.com"
          git add data/sample-events.json

          # Only commit if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ü§ñ Update events data from AI scraper [automated]"
            git push
            echo "‚úÖ Changes pushed to repository"
          fi

      - name: Upload results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: aggregation-results
          path: |
            automation/events_*.json
            automation/ai_events_*.json
          retention-days: 30

      - name: Clean up credentials
        if: always()
        run: |
          cd automation
          rm -f google-service-account.json
