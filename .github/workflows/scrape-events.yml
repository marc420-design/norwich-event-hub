name: Scrape Real-Time Events

on:
  # Run automatically every day at 6 AM UTC
  schedule:
    - cron: '0 6 * * *'

  # Allow manual trigger from GitHub Actions tab
  workflow_dispatch:

  # Run on push to main (for testing)
  push:
    branches:
      - main
      - master
    paths:
      - 'automation/**'
      - '.github/workflows/scrape-events.yml'

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 python-dotenv lxml

      - name: Run event scraper
        run: |
          cd automation
          python real-time-scraper.py
        env:
          # Google Apps Script URL from config
          GOOGLE_APPS_SCRIPT_URL: https://script.google.com/macros/s/AKfycbwUqbC7ZkAqO5w0POhRd_hBDBPrZDKV0I_K43lmdKbLrL0rjAAoEYwgZpc_xuzs1x0M/exec

      - name: Summary
        run: |
          echo "‚úÖ Event scraping completed successfully!"
          echo "üìä New events have been posted to Google Sheets"
          echo "üîç Check your admin dashboard to review pending events"
          echo "üåê Admin: https://norwicheventshub.com/admin"

  # Optional: Notify on failure
  notify-on-failure:
    runs-on: ubuntu-latest
    needs: scrape-and-update
    if: failure()
    steps:
      - name: Notification
        run: |
          echo "‚ùå Event scraping failed!"
          echo "Check the logs above for details"
